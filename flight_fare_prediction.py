# -*- coding: utf-8 -*-
"""Flight_fare_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/164JKp3D-cmEf2kfJOaZtiCuFoRIsBCbb
"""

from google.colab import drive

drive.mount("/content/gdrive")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_excel(r"/content/gdrive/MyDrive/ml/Data_Train.xlsx")

"""# lets read the data"""

df.head(5)

df.tail(5)

"""#lets deal with missing values

"""

df.info()

df.isnull().sum()

df["Route"].isnull().sum()

df[df["Route"].isnull()]

df["Total_Stops"].isnull().sum()

df[df["Total_Stops"].isnull()]

df.dropna(inplace=True)

df.isnull().sum()

df.dtypes

df.info(memory_usage="deep")

train_data = df.copy()

"""# lets perform preprocess and extract derived attributes from date of Journey"""

train_data["Date_of_Journey"]

# we need to extract day, month and year uding the dt method

train_data["Date_of_Journey"] = pd.to_datetime(train_data["Date_of_Journey"])

train_data["Day_of_Journey"] = train_data["Date_of_Journey"].dt.day
train_data["Month_of_Journey"] = train_data["Date_of_Journey"].dt.month
train_data["Year_of_Journey"] = train_data["Date_of_Journey"].dt.year

df.head(5)

train_data.drop("Date_of_Journey",axis=1,inplace=True)

train_data.head(5)

"""# lets clean arrival and dept time and extract derived attaributes from it"""

train_data.head(5)

train_data["Dep_Time"]

train_data["Dep_Time"] = pd.to_datetime(train_data["Dep_Time"])

train_data["Dep_Time"]

train_data["Dep_Time_Hr"] = train_data["Dep_Time"].dt.hour

train_data["Dep_Time_Min"] = train_data["Dep_Time"].dt.minute

train_data.head(5)

train_data.drop("Dep_Time",axis=1,inplace=True)

train_data.head(6)

train_data["Arrival_Time"]

train_data["Arrival_Time"] = pd.to_datetime(train_data["Arrival_Time"])

train_data["Arrival_Time"]

train_data["Arrival_Time_Hr"] = train_data["Arrival_Time"].dt.hour
train_data["Arrival_Time_Min"] = train_data["Arrival_Time"].dt.minute

train_data.drop("Arrival_Time",axis=1,inplace=True)

train_data.head()

"""# lets analyze dep time hour and find out during which time of day we have most traffic"""

train_data["Dep_Time_Hr"]

def analyze(x):

  if x>5 and x<=7:
    return "Early Morning"
  elif x>7 and x<=11:
    return "Morning"
  elif x>11 and x<=15:
    return "Noon"
  elif x>15 and x<=19:
    return "Evening"
  elif x>19 and x<=24:
    return "Night"
  else:
    return "Late Night"

train_data["Dep_Time_Hr"].apply(analyze).value_counts().plot(kind="bar", color="blue")

"""# Handle the duration feature"""

train_data["Duration"]

def repair(x):
  if 'h' not in x:
    x = '0h ' + x
  elif 'm' not in x:
    x = x + ' 0m'
  return x

train_data["Duration"] = train_data["Duration"].apply(repair)

train_data["Duration"]

"8h 20m".split(' ')

"8h 20m".split(' ')[0]

"8h 20m".split(' ')[0][0:-1]

"8h 20m".split(' ')[1][0:-1]

train_data["Duration_min"] = train_data["Duration"].apply(lambda x: x.split(' ')[1][0:-1])

train_data["Duration_hr"] = train_data["Duration"].apply(lambda x: x.split(' ')[0][0:-1])

train_data.head(5)

eval("4*60+45*1")

train_data["Total_Duration_minutes"] = train_data["Duration"].str.replace("h","*60").str.replace(" ","+").str.replace("m","*1").apply(eval)

train_data["Total_Duration_minutes"]

train_data.head(5)

sns.scatterplot(x="Total_Duration_minutes" , y = "Price" , data= train_data)

sns.scatterplot(x="Total_Duration_minutes" , y = "Price" , data= train_data , hue = "Total_Stops")

sns.lmplot(x="Total_Duration_minutes" , y = "Price" , data= train_data)

"""# On which route jet airways is extremely used"""

train_data.head(5)

df['Airline'] == 'Jet Airways'

df[df['Airline'] == 'Jet Airways'].groupby("Route").size().sort_values(ascending=False)

plt.figure(figsize=(10,5))
sns.boxplot(x="Airline", y="Price", data=train_data.sort_values("Price", ascending=False))
plt.xticks(rotation='vertical')

"""# lets perform feature engineering"""

train_data.head(2)

train_data["Source"].unique()

train_data["Source"].apply(lambda x : 1 if x=="Banglore" else 0)

for i  in train_data["Source"].unique():
  train_data["Source_"+i] = train_data["Source"].apply(lambda x : 1 if x==i else 0)

train_data.head(3)

train_data['Airline'].unique()

train_data['Airline'].nunique()

train_data.groupby(['Airline'])['Price'].mean().sort_values().index

ar = train_data.groupby(['Airline'])['Price'].mean().sort_values().index

ar

dict = {val:key for key,val in enumerate(ar)}

dict

train_data["Airline"] = train_data["Airline"].map(dict)

train_data.head(3)

train_data["Destination"]

train_data["Destination"].unique()

train_data["Destination"].str.replace('New Delhi','Delhi')

ar = train_data.groupby(["Destination"])['Price'].mean().sort_values().index

ar

dict = {key:val for val,key in enumerate(ar)}

dict

train_data["Destination"] = train_data["Destination"].map(dict)

train_data.head(3)

"""# Perform label encoding"""

tr = train_data["Total_Stops"].unique()

tr

def change(x):
  if x=='non-stop':
    return 0
  elif x=='1 stop':
    return 1
  elif x=='2 stops':
    return 2
  elif x=='3 stops':
    return 3
  elif x=='4 stops':
    return 4

train_data['Total_Stops'] = train_data['Total_Stops'].apply(change)

train_data.head(4)

"""# Finally dropping irrelevant features"""

train_data.columns

train_data.drop(columns=['Route','Duration','Additional_Info','Total_Duration_minutes','Source'],axis=1,inplace=True)

train_data.head(3)

"""# Outlier Detection"""

train_data.head(3)

def plot(df, x):
  fig, (ax1,ax2,ax3) = plt.subplots(3,1)

  sns.distplot(df[x], ax = ax1)
  sns.boxplot(df[x], ax = ax2)
  sns.distplot(df[x], ax = ax3, kde=False)

plot(train_data, 'Price')

q1 = train_data['Price'].quantile(0.25)
q2 = train_data['Price'].quantile(0.75)

iqr = q2 -q1

max = q2 + (1.5*iqr)
min = q1 - (1.5*iqr)

print(max)
print(min)

price = [i for i in train_data['Price'] if i > max or i < min]

price

len(price)

train_data['Price'] = np.where(train_data['Price']>35000, train_data['Price'].median(), train_data['Price'])

plot(train_data, 'Price')

"""#lets perform feature selection"""

train_data.head(3)

X = train_data.drop(['Price'],axis=1)

y = train_data['Price']

X

y

from sklearn.feature_selection import mutual_info_regression

imp = mutual_info_regression(X,y)

imp

imp = pd.DataFrame(imp, index=X.columns)

imp

imp.columns = ['importance']

imp

imp.sort_values(by='importance', ascending=False)

train_data.drop(['Year_of_Journey'],axis=1,inplace=True)

train_data.head(3)

from sklearn.ensemble import RandomForestRegressor

from sklearn.model_selection import train_test_split

X_train,X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)

ml_model = RandomForestRegressor()

ml_model.fit(X_train,y_train)

y_pred = ml_model.predict(X_test)

y_pred

from sklearn import metrics

metrics.r2_score(y_test,y_pred)

"""#Lets save our model"""

import pickle

file = open(r'/content/gdrive/MyDrive/ml/rf_random.pkl' , 'wb')

# dump information to that file
pickle.dump(ml_model , file)

model = open(r'/content/gdrive/MyDrive/ml/rf_random.pkl' , 'rb')

forest = pickle.load(model)

import pickle

# ... (previous code to create ml_model)

# Open the file in write binary mode to store the model
file = open(r'/content/gdrive/MyDrive/ml/rf_random.pkl', 'wb')

# Dump the model into the file
pickle.dump(ml_model, file)

# Close the file to ensure data is written and resources are released
file.close()

# Open the file in read binary mode to load the model
model = open(r'/content/gdrive/MyDrive/ml/rf_random.pkl', 'rb')

# Load the model from the file
forest = pickle.load(model)

# Close the file after loading
model.close()

y_pred2 = forest.predict(X_test)

metrics.r2_score(y_test , y_pred2)

def mape(y_true , y_pred):
    y_true , y_pred = np.array(y_true) , np.array(y_pred)
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

mape(y_test , y_pred)

from sklearn import metrics

def predict(ml_model):
    model = ml_model.fit(X_train , y_train)
    print('Training score : {}'.format(model.score(X_train , y_train)))
    y_predection = model.predict(X_test)
    print('predictions are : {}'.format(y_predection))
    print('\n')
    r2_score = metrics.r2_score(y_test , y_predection)
    print('r2 score : {}'.format(r2_score))
    print('MAE : {}'.format(metrics.mean_absolute_error(y_test , y_predection)))
    print('MSE : {}'.format(metrics.mean_squared_error(y_test , y_predection)))
    print('RMSE : {}'.format(np.sqrt(metrics.mean_squared_error(y_test , y_predection))))
    print('MAPE : {}'.format(mape(y_test , y_predection)))
    sns.distplot(y_test - y_predection)

predict(RandomForestRegressor())

from sklearn.tree import DecisionTreeRegressor

predict(DecisionTreeRegressor())

from sklearn.linear_model import LinearRegression

predict(LinearRegression())

from sklearn.linear_model import LogisticRegression

predict(LogisticRegression())

